{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYQE37rOc539"
   },
   "source": [
    "# 5x5 Via array example\n",
    "\n",
    "**Author:** Allan Sánchez Masís\n",
    "\n",
    "**Last update by:** Allan Sánchez Masís\n",
    "\n",
    "**Link of database:**https://www.tet.tuhh.de/en/si-pi-database/\n",
    "\n",
    "**Link of papers:**\n",
    "<ul>\n",
    "    <li>https://ieeexplore.ieee.org/document/9361755</li>\n",
    "    <li>https://ieeexplore.ieee.org/document/9505202</li>\n",
    "    <li>https://ieeexplore.ieee.org/document/10375594</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uCtcT9FFQ_X"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "yqk8N_AeFRFX"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers         import Dense, Dropout, Flatten\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks      import EarlyStopping, Callback\n",
    "from keras.layers         import Conv2D, MaxPooling2D, Conv1D\n",
    "from keras                import backend as K\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.externals.joblib import dump, load\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTKRjmXBOteT"
   },
   "source": [
    "## Data split and import data\n",
    "Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+00 2.00e-02 4.34e+00 1.30e+01 7.15e+00 7.55e+00 2.80e+01 3.40e+01]]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "def get_values_and_header(csv_matrix):\n",
    "    csv_matrix=csv_matrix.values\n",
    "    matrix_values=csv_matrix[1:,0:]\n",
    "    matrix_values=np.asfarray(matrix_values,float)\n",
    "    vector_header=csv_matrix[0,0:]\n",
    "    return matrix_values, vector_header\n",
    "\n",
    "\n",
    "def separador_de_features(features_amount,dataset,features):\n",
    "    contafeatures=0\n",
    "    features=np.reshape(features, (1, features_amount))\n",
    "    print(features)\n",
    "\n",
    "    for i in range(0,len(dataset)):\n",
    "        for j in range(0,features_amount):\n",
    "            if features[contafeatures][j]!=dataset[i][j]:\n",
    "                son_iguales=False\n",
    "                break\n",
    "            else:\n",
    "                son_iguales=True\n",
    "        if son_iguales==False:\n",
    "            dataset_sub_i_2d=np.reshape(dataset[i,0:features_amount], (1, features_amount))\n",
    "            features=np.concatenate((features,dataset_sub_i_2d))\n",
    "            contafeatures=contafeatures+1\n",
    "    return features\n",
    "\n",
    "\n",
    "def train_test_full(features_amount,dataset,x_test,outputs_amount):\n",
    "        conta_iguales=0\n",
    "        data_test_full=np.ones((1,features_amount+1+outputs_amount))\n",
    "        print(data_test_full)\n",
    "\n",
    "        for i in range(0,len(x_test)):\n",
    "            #rows_dataset=len(dataset)\n",
    "            for j in range(0,len(dataset)):\n",
    "                    for k in range(0,features_amount):\n",
    "                        if x_test[i][k]!=dataset[j-conta_iguales][k]:\n",
    "                            son_iguales=False\n",
    "                            break\n",
    "                        else:\n",
    "                            son_iguales=True\n",
    "                    if son_iguales==True:\n",
    "                        dataset_sub_i_2d=np.reshape(dataset[j-conta_iguales,0:features_amount+1+outputs_amount], (1, features_amount+1+outputs_amount))\n",
    "                        data_test_full=np.concatenate((data_test_full,dataset_sub_i_2d))\n",
    "                        dataset=np.delete(dataset, j-conta_iguales, axis=0)\n",
    "                        conta_iguales=conta_iguales+1\n",
    "            print(str((i+1)/len(x_test)*100)+\"%\")\n",
    "            conta_iguales=0\n",
    "        data_test_full=data_test_full[1:len(data_test_full),:]\n",
    "        return data_test_full, dataset\n",
    "\n",
    "\n",
    "dataset = pandas.read_csv(\"C:/path/little_sample_to_prove.csv\", header=None)\n",
    "dataset, vector_header=get_values_and_header(dataset)\n",
    "\n",
    "#dataset= np.array([[1,2,3,1,3],[1,2,3,2,4],[1,2,7,1,5],[1,2,7,2,6],[1,2,1,1,7],[1,2,1,2,17],[1,2,1,2,17],[1,44,1,1,7],[1,44,1,2,17]])\n",
    "#x_test=np.array([[1,2,3],[1,2,1]])\n",
    "features_amount=8\n",
    "outputs_amount=12\n",
    "\n",
    "features=dataset[0,0:features_amount]\n",
    "\n",
    "features=separador_de_features(features_amount,dataset,features)\n",
    "\n",
    "x_train, x_test = train_test_split(    \n",
    "    features, test_size=0.15, random_state=1)\n",
    "\n",
    "#np.savetxt(\"training_set_re_im_caso_simple_random_state_1.csv\",x_train,delimiter=\",\")\n",
    "#np.savetxt(\"testing_set_re_im_caso_simple_random_state_1.csv\",x_test,delimiter=\",\")\n",
    "\n",
    "vector_header=np.reshape(vector_header,(1,len(vector_header)))\n",
    "\n",
    "\n",
    "data_test_full, dataset=train_test_full(features_amount,dataset,x_test,outputs_amount)\n",
    "\n",
    "\n",
    "data_test_full=np.append(vector_header,data_test_full,axis=0)\n",
    "dataset=np.append(vector_header,dataset,axis=0)\n",
    "\n",
    "np.savetxt(\"testing_set_re_im_array_seed_1.csv\",data_test_full,delimiter=\",\",fmt='%s')\n",
    "np.savetxt(\"training_set_re_im_array_seed_1_full.csv\",dataset,delimiter=\",\",fmt='%s')\n",
    "#'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 21)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+00 2.00e-02 4.34e+00 1.30e+01 7.15e+00 7.55e+00 2.80e+01 3.40e+01]]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = pandas.read_csv(\"C:/path/training_set_re_im_array_seed_1_full.csv\", header=None)\n",
    "dataset, vector_header=get_values_and_header(dataset)\n",
    "\n",
    "#dataset= np.array([[1,2,3,1,3],[1,2,3,2,4],[1,2,7,1,5],[1,2,7,2,6],[1,2,1,1,7],[1,2,1,2,17],[1,2,1,2,17],[1,44,1,1,7],[1,44,1,2,17]])\n",
    "#x_test=np.array([[1,2,3],[1,2,1]])\n",
    "features_amount=8\n",
    "outputs_amount=12\n",
    "\n",
    "features=dataset[0,0:features_amount]\n",
    "\n",
    "features=separador_de_features(features_amount,dataset,features)\n",
    "\n",
    "x_train, x_test = train_test_split(    \n",
    "    features, test_size=3/17, random_state=1)\n",
    "\n",
    "#np.savetxt(\"training_set_re_im_caso_simple_random_state_1.csv\",x_train,delimiter=\",\")\n",
    "#np.savetxt(\"testing_set_re_im_caso_simple_random_state_1.csv\",x_test,delimiter=\",\")\n",
    "\n",
    "vector_header=np.reshape(vector_header,(1,len(vector_header)))\n",
    "\n",
    "data_test_full, dataset=train_test_full(features_amount,dataset,x_test,outputs_amount)\n",
    "\n",
    "data_test_full=np.append(vector_header,data_test_full,axis=0)\n",
    "dataset=np.append(vector_header,dataset,axis=0)\n",
    "\n",
    "np.savetxt(\"validation_set_re_im_array_seed_1_full.csv\",data_test_full,delimiter=\",\",fmt='%s')\n",
    "np.savetxt(\"training_set_re_im_array_seed_1_full.csv\",dataset,delimiter=\",\",fmt='%s')\n",
    "#'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into 80% training and 20% testing\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(x_train.shape)\n",
    "#print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load splitted dataset\n",
    "Load data $x_w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\allan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700000, 8)\n",
      "(700000, 12)\n"
     ]
    }
   ],
   "source": [
    "dataframe = pandas.read_csv(r\"C:/path/training_set_re_im_array_seed_1_array_conmls.csv\", header=None)\n",
    "dataframe=dataframe.values\n",
    "dataframe=np.asfarray(dataframe[1:,0:],float)\n",
    "    \n",
    "    #dataframe=np.delete(dataframe,7,1)\n",
    "x_train = dataframe[:,0:8]\n",
    "y_train = dataframe[:,8:]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(r\"C:/path/testing_set_re_im_array_seed_1_array_conmls.csv\", header=None)\n",
    "dataframe=dataframe.values\n",
    "dataframe=np.asfarray(dataframe[1:,0:],float)\n",
    "    \n",
    "    #dataframe=np.delete(dataframe,7,1)\n",
    "x_test = dataframe[:,0:8]\n",
    "y_test = dataframe[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(r\"C:/path/validation_set_re_im_array_seed_1_array_conmls.csv\", header=None)\n",
    "dataframe=dataframe.values\n",
    "dataframe=np.asfarray(dataframe[1:,0:],float)\n",
    "    \n",
    "    #dataframe=np.delete(dataframe,7,1)\n",
    "x_val = dataframe[:,0:8]\n",
    "y_val = dataframe[:,8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset\n",
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x=\\frac{x-\\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['standar_input.bin']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #standarization\n",
    "\n",
    "standar_1=StandardScaler().fit(x_train)\n",
    "x_train=standar_1.transform(x_train)\n",
    "x_val=standar_1.transform(x_val)\n",
    "\n",
    "x_test=standar_1.transform(x_test)\n",
    "\n",
    "\n",
    "dump(standar_1, 'standar_input.bin', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700000 samples, validate on 150000 samples\n",
      "Epoch 1/3\n",
      " - 41s - loss: 0.0018 - accuracy: 0.9259 - val_loss: 4.5908e-04 - val_accuracy: 0.9568\n",
      "Epoch 2/3\n",
      " - 42s - loss: 4.1076e-04 - accuracy: 0.9590 - val_loss: 3.6996e-04 - val_accuracy: 0.9621\n",
      "Epoch 3/3\n",
      " - 40s - loss: 3.5162e-04 - accuracy: 0.9624 - val_loss: 3.7395e-04 - val_accuracy: 0.9613\n",
      "Test loss: 0.0005\n",
      "Test accuracy: 0.9579\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=3, verbose=2, validation_data=(x_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "\n",
    "model.save(\"model_.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 50)                450       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 12)                612       \n",
      "=================================================================\n",
      "Total params: 3,612\n",
      "Trainable params: 3,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = load_model('model_.h5')\n",
    "standar_1=load('standar_input.bin')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plate_thickness,loss_tan,epsilon_r,antipad_radius,cavity_tickness,pad_radius,pitch,freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(r\"C:/path/testing_set_re_im_array_seed_1_array_conmls.csv\", header=None)\n",
    "dataframe=dataframe.values\n",
    "dataframe=np.asfarray(dataframe[1:,0:],float)\n",
    "    \n",
    "\n",
    "x_example = dataframe[0,0:8]\n",
    "y_expected = dataframe[0,8:]\n",
    "x_example = x_example.reshape(1, -1)\n",
    "y_expected = y_expected.reshape(1, -1)\n",
    "\n",
    "print(\"Entrada de ejemplo: \")\n",
    "print(x_example)\n",
    "print(x_example.shape)\n",
    "\n",
    "x_example=standar_1.transform(x_example)\n",
    "\n",
    "print(\"Salida esperada de ejemplo ejemplo: \")\n",
    "print(y_expected)\n",
    "print(y_expected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reS(11),reS(21),reS(13 1),reS(13 2),reS(23 1),reS(23 2),imS(11),imS(21),imS(13 1),imS(13 2),imS(23 1),imS(23 2)\n",
    "y_predicted = model.predict(x_example)\n",
    "print(\"Salida predicha con el ejemplo: \")\n",
    "print(y_predicted)\n",
    "print(y_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_example = dataframe[0:200,0:8]\n",
    "y_expected = dataframe[0:200,8:]\n",
    "#x_example = x_example.reshape(1, -1)\n",
    "#y_expected = y_expected.reshape(1, -1)\n",
    "\n",
    "print(\"Entrada de ejemplo: \")\n",
    "print(x_example)\n",
    "print(x_example.shape)\n",
    "\n",
    "x_example=standar_1.transform(x_example)\n",
    "\n",
    "print(\"Salida esperada de ejemplo ejemplo: \")\n",
    "print(y_expected)\n",
    "print(y_expected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reS(11),reS(21),reS(13 1),reS(13 2),reS(23 1),reS(23 2),imS(11),imS(21),imS(13 1),imS(13 2),imS(23 1),imS(23 2)\n",
    "y_predicted = model.predict(x_example)\n",
    "print(\"Salida predicha con el ejemplo: \")\n",
    "print(y_predicted)\n",
    "print(y_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_plot=y_predicted[:,0]\n",
    "print(y_predicted_plot.shape)\n",
    "\n",
    "y_expected_plot=y_expected[:,0]\n",
    "print(y_expected_plot.shape)\n",
    "\n",
    "\n",
    "x_plot = dataframe[0:200,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la figura y los ejes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotear el primer array\n",
    "plt.plot(x_plot, y_expected_plot,  label='Esperado', color='blue')\n",
    "# Plotear el segundo array sobre el mismo gráfico\n",
    "plt.plot(x_plot, y_predicted_plot, label='Predicho', color='red')\n",
    "\n",
    "# Añadir leyenda y etiquetas\n",
    "plt.legend()\n",
    "plt.title(\"Comparación\")\n",
    "plt.xlabel(\"Frecuencia (GHz)\")\n",
    "plt.ylabel(\"Parte real reflexion\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3uCtcT9FFQ_X",
    "pIkXmZTuOteT",
    "ApdR-jBag2UX",
    "F0SkWkF3jGQ3"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
